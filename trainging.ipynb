{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14bc130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\msi\\documents\\uni\\estocaicos\\paper\\proyectospanishsign\\myenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy opencv-python scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a23be11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3057 - loss: 2.8645 - val_accuracy: 0.5932 - val_loss: 2.3840\n",
      "Epoch 2/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7210 - loss: 1.7987 - val_accuracy: 0.8137 - val_loss: 1.2184\n",
      "Epoch 3/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8629 - loss: 0.8173 - val_accuracy: 0.9068 - val_loss: 0.5814\n",
      "Epoch 4/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9367 - loss: 0.4004 - val_accuracy: 0.9316 - val_loss: 0.3651\n",
      "Epoch 5/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9595 - loss: 0.2456 - val_accuracy: 0.9544 - val_loss: 0.2685\n",
      "Epoch 6/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.1678 - val_accuracy: 0.9696 - val_loss: 0.2074\n",
      "Epoch 7/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.1192 - val_accuracy: 0.9772 - val_loss: 0.1675\n",
      "Epoch 8/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0890 - val_accuracy: 0.9829 - val_loss: 0.1406\n",
      "Epoch 9/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0672 - val_accuracy: 0.9848 - val_loss: 0.1190\n",
      "Epoch 10/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0517 - val_accuracy: 0.9848 - val_loss: 0.1055\n",
      "Epoch 11/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0415 - val_accuracy: 0.9848 - val_loss: 0.0944\n",
      "Epoch 12/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0328 - val_accuracy: 0.9848 - val_loss: 0.0854\n",
      "Epoch 13/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0267 - val_accuracy: 0.9848 - val_loss: 0.0775\n",
      "Epoch 14/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0220 - val_accuracy: 0.9848 - val_loss: 0.0748\n",
      "Epoch 15/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0184 - val_accuracy: 0.9848 - val_loss: 0.0691\n",
      "Epoch 16/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0156 - val_accuracy: 0.9848 - val_loss: 0.0635\n",
      "Epoch 17/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0134 - val_accuracy: 0.9867 - val_loss: 0.0621\n",
      "Epoch 18/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0116 - val_accuracy: 0.9848 - val_loss: 0.0618\n",
      "Epoch 19/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0102 - val_accuracy: 0.9867 - val_loss: 0.0585\n",
      "Epoch 20/20\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0090 - val_accuracy: 0.9867 - val_loss: 0.0569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. CARGAR CSV\n",
    "# -------------------------------------------------------\n",
    "df = pd.read_csv(\"dataset_with_noise.csv\")\n",
    "\n",
    "# Ruta de la imagen\n",
    "paths = df[\"image_path\"].values\n",
    "labels = df[\"label\"].values\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. CARGAR Y NORMALIZAR IMÁGENES\n",
    "# -------------------------------------------------------\n",
    "IM_SIZE = 64  # tamaño estándar para reducir dimensionalidad\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (IM_SIZE, IM_SIZE))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    return img.flatten()  # vector\n",
    "\n",
    "X = np.array([load_image(p) for p in paths])\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. ENCODE LABELS\n",
    "# -------------------------------------------------------\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "y = to_categorical(y)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4. PCA PARA REDUCIR VARIABLES ****  \n",
    "# -------------------------------------------------------\n",
    "pca = PCA(n_components=100)   # reduce la imagen a 100 features\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5. TRAIN / TEST SPLIT\n",
    "# -------------------------------------------------------\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    X_pca, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6. RED NEURONAL SIMPLE\n",
    "# -------------------------------------------------------\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(100,)),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(y.shape[1], activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 7. ENTRENAMIENTO\n",
    "# -------------------------------------------------------\n",
    "model.fit(\n",
    "    Xtrain, ytrain,\n",
    "    validation_data=(Xtest, ytest),\n",
    "    batch_size=32,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 8. GUARDAR MODELO Y PCA\n",
    "# -------------------------------------------------------\n",
    "model.save(\"sign_model.h5\")\n",
    "np.save(\"pca_components.npy\", pca.components_)\n",
    "np.save(\"pca_mean.npy\", pca.mean_)\n",
    "np.save(\"label_classes.npy\", le.classes_)\n",
    "print(\"Modelo guardado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07000af",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6dd5212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA dimensiones reducidas: 9\n",
      "Accuracy en validación: 0.9961977186311787\n",
      "Modelo Random Forest guardado como rf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# CARGA DEL CSV\n",
    "# -------------------------------------------------------------\n",
    "df = pd.read_csv(\"dataset_with_noise.csv\")\n",
    "\n",
    "# Etiquetas variable objetivo\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Guardar las clases\n",
    "label_classes = np.unique(y)\n",
    "np.save(\"rf_label_classes.npy\", label_classes)\n",
    "\n",
    "# Convertir letras a índices\n",
    "label_to_idx = {c: i for i, c in enumerate(label_classes)}\n",
    "y_idx = y.map(label_to_idx)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# FEATURES NUMÉRICAS (TODO EXCEPTO PATH Y LABEL)\n",
    "# -------------------------------------------------------------\n",
    "feature_cols = [\n",
    "    \"x\",\"y\",\"z\",\n",
    "    \"thumb\",\"fore\",\"index\",\"ring\",\"little\",\n",
    "    \"thumb2\",\"fore2\",\"index2\",\"ring2\",\"little2\",\n",
    "    \"keycode\",\"gs1\",\"gs2\",\"sign\",\n",
    "    \"giroX\",\"giroY\",\"giroZ\"\n",
    "]\n",
    "\n",
    "X = df[feature_cols].values.astype(\"float32\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# NORMALIZACIÓN\n",
    "# -------------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Guardar scaler\n",
    "joblib.dump(scaler, \"rf_scaler.pkl\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# PCA\n",
    "# -------------------------------------------------------------\n",
    "pca = PCA(n_components=0.95, svd_solver='full')  # conserva 95% varianza\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "np.save(\"rf_pca_components.npy\", pca.components_)\n",
    "np.save(\"rf_pca_mean.npy\", pca.mean_)\n",
    "\n",
    "print(\"PCA dimensiones reducidas:\", X_pca.shape[1])\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# SPLIT\n",
    "# -------------------------------------------------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_pca, y_idx, test_size=0.2, random_state=42, stratify=y_idx\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# RANDOM FOREST\n",
    "# -------------------------------------------------------------\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# EVALUACIÓN\n",
    "# -------------------------------------------------------------\n",
    "acc = rf.score(X_val, y_val)\n",
    "print(\"Accuracy en validación:\", acc)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# GUARDAR MODELO\n",
    "# -------------------------------------------------------------\n",
    "joblib.dump(rf, \"rf_model.pkl\")\n",
    "\n",
    "print(\"Modelo Random Forest guardado como rf_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3472e7e",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a60ec1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== MÉTRICAS DEL MODELO SVM =====\n",
      "Accuracy:  0.9954\n",
      "Precision: 0.9956\n",
      "Recall:    0.9954\n",
      "F1-Score:  0.9954\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       1.00      0.96      0.98        25\n",
      "           2       1.00      0.96      0.98        25\n",
      "           3       0.96      1.00      0.98        25\n",
      "           4       1.00      1.00      1.00        25\n",
      "           5       1.00      1.00      1.00        25\n",
      "           6       1.00      1.00      1.00        26\n",
      "           7       1.00      1.00      1.00        26\n",
      "           8       1.00      1.00      1.00        25\n",
      "           9       1.00      1.00      1.00        25\n",
      "          10       1.00      1.00      1.00        26\n",
      "          11       1.00      1.00      1.00        25\n",
      "          12       1.00      1.00      1.00        25\n",
      "          13       1.00      1.00      1.00        25\n",
      "          14       1.00      1.00      1.00        26\n",
      "          15       1.00      1.00      1.00        25\n",
      "          16       1.00      1.00      1.00        25\n",
      "          17       1.00      1.00      1.00        25\n",
      "          18       1.00      1.00      1.00        25\n",
      "          19       1.00      1.00      1.00        26\n",
      "          20       1.00      1.00      1.00        51\n",
      "          21       1.00      1.00      1.00        25\n",
      "          22       1.00      1.00      1.00        25\n",
      "          23       1.00      0.96      0.98        26\n",
      "          24       0.96      1.00      0.98        25\n",
      "\n",
      "    accuracy                           1.00       657\n",
      "   macro avg       1.00      1.00      1.00       657\n",
      "weighted avg       1.00      1.00      1.00       657\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0 24  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 1  0 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 26  0  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 26  0  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 51  0  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0\n",
      "   0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25\n",
      "   1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  25]]\n",
      "\n",
      "✔ Modelo SVM entrenado, evaluado y guardado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_svm(csv_path=\"dataset.csv\"):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 1. Cargar y procesar imágenes\n",
    "    # -------------------------------------\n",
    "    images = []\n",
    "    for path in df[\"image_path\"]:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        img = img.flatten() / 255.0\n",
    "        images.append(img)\n",
    "\n",
    "    images = np.array(images)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 2. Features numéricos del CSV\n",
    "    # -------------------------------------\n",
    "    numeric_cols = [\n",
    "        \"x\",\"y\",\"z\",\n",
    "        \"thumb\",\"fore\",\"index\",\"ring\",\"little\",\n",
    "        \"thumb2\",\"fore2\",\"index2\",\"ring2\",\"little2\",\n",
    "        \"gs1\",\"gs2\",\n",
    "        \"giroX\",\"giroY\",\"giroZ\"\n",
    "    ]\n",
    "\n",
    "    csv_features = df[numeric_cols].values.astype(float)\n",
    "\n",
    "    # unir imagen + csv\n",
    "    X = np.hstack([images, csv_features])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 3. Labels\n",
    "    # -------------------------------------\n",
    "    labels = df[\"label\"]\n",
    "    label_classes = np.unique(labels)\n",
    "    label_to_idx = {c: i for i, c in enumerate(label_classes)}\n",
    "    y = np.array([label_to_idx[l] for l in labels])\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 4. Train Test Split\n",
    "    # -------------------------------------\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.25, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 5. Normalizar\n",
    "    # -------------------------------------\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 6. PCA\n",
    "    # -------------------------------------\n",
    "    pca = PCA(0.97)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 7. Entrenar SVM\n",
    "    # -------------------------------------\n",
    "    svm = SVC(kernel=\"rbf\", probability=True)\n",
    "    svm.fit(X_train_pca, y_train)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 8. Evaluar\n",
    "    # -------------------------------------\n",
    "    y_pred = svm.predict(X_test_pca)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n===== MÉTRICAS DEL MODELO SVM =====\")\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(\"\\nReporte de Clasificación:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    print(\"Matriz de Confusión:\")\n",
    "    print(cm)\n",
    "\n",
    "    # -------------------------------------\n",
    "    # 9. Guardar modelos\n",
    "    # -------------------------------------\n",
    "    joblib.dump(svm, \"svm_model.pkl\")\n",
    "    joblib.dump(scaler, \"svm_scaler.pkl\")\n",
    "    joblib.dump(pca, \"svm_pca.pkl\")\n",
    "    np.save(\"svm_label_classes.npy\", label_classes)\n",
    "\n",
    "    print(\"\\n✔ Modelo SVM entrenado, evaluado y guardado correctamente.\")\n",
    "\n",
    "train_svm(\"dataset_with_noise.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b37f799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red Neuronal</td>\n",
       "      <td>0.9867</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.9860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.9960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.9954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Modelo  Accuracy  Precision  Recall  F1-Score\n",
       "0   Red Neuronal    0.9867     0.9860  0.9860    0.9860\n",
       "1  Random Forest    0.9962     0.9960  0.9960    0.9960\n",
       "2            SVM    0.9954     0.9956  0.9954    0.9954"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo en Accuracy: Random Forest\n",
      "Mejor modelo en Precision: Random Forest\n",
      "Mejor modelo en Recall: Random Forest\n",
      "Mejor modelo en F1-Score: Random Forest\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Métricas de cada modelo (ajusta estos valores con los que realmente obtuviste)\n",
    "metrics = {\n",
    "    \"Modelo\": [\"Red Neuronal\", \"Random Forest\", \"SVM\"],\n",
    "    \"Accuracy\": [\n",
    "        0.9867,   # ejemplo: accuracy validación Red Neuronal\n",
    "        0.9962,   # accuracy validación Random Forest (del print)\n",
    "        0.9954    # accuracy SVM (del print)\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        0.9860,   # pon aquí la precisión de la red si la calculas\n",
    "        0.9960,   # si calculas precision para RF\n",
    "        0.9956    # precision SVM\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        0.9860,   # recall red\n",
    "        0.9960,   # recall RF\n",
    "        0.9954    # recall SVM\n",
    "    ],\n",
    "    \"F1-Score\": [\n",
    "        0.9860,   # F1 red\n",
    "        0.9960,   # F1 RF\n",
    "        0.9954    # F1 SVM\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "display(df_metrics)\n",
    "\n",
    "# Mostrar también cuál es el mejor modelo por cada métrica\n",
    "best_accuracy_model = df_metrics.loc[df_metrics[\"Accuracy\"].idxmax(), \"Modelo\"]\n",
    "best_precision_model = df_metrics.loc[df_metrics[\"Precision\"].idxmax(), \"Modelo\"]\n",
    "best_recall_model = df_metrics.loc[df_metrics[\"Recall\"].idxmax(), \"Modelo\"]\n",
    "best_f1_model = df_metrics.loc[df_metrics[\"F1-Score\"].idxmax(), \"Modelo\"]\n",
    "\n",
    "print(\"Mejor modelo en Accuracy:\", best_accuracy_model)\n",
    "print(\"Mejor modelo en Precision:\", best_precision_model)\n",
    "print(\"Mejor modelo en Recall:\", best_recall_model)\n",
    "print(\"Mejor modelo en F1-Score:\", best_f1_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
